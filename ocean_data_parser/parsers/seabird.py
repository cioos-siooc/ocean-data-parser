"""
This module contains all the different tools used to 
handle the different [Seabird Scientific](https://www.seabird.com) 
file formats generated by the different proprietary softwares. 

"""

import difflib
import json
import logging
import os
import re

import pandas as pd
import xarray
import xmltodict
from pyexpat import ExpatError

from ocean_data_parser.parsers.utils import convert_datetime_str, standardize_dataset
from ocean_data_parser.vocabularies.load import seabird_vocabulary

logger = logging.getLogger(__name__)

SBE_TIME_FORMAT = "%b %d %Y %H:%M:%S"  # Jun 23 2016 13:51:30
sbe_time = re.compile(
    r"(?P<time>\w\w\w\s+\d{1,2}\s+\d{1,4}\s+\d\d\:\d\d\:\d\d)(?P<comment>.*)"
)

var_dtypes = {
    "date": str,
    "bottle": str,
    "Flag": int,
    "flag": int,
    "stats": str,
    "scan": int,
}
xml_sections = {"#": "instrument_xml", "*": "data_xml"}

sbe_data_processing_modules = [
    "datcnv",
    "filter",
    "align",
    "celltm",
    "loopedit",
    "derive",
    "Derive",
    "binavg",
    "split",
    "strip",
    "section",
    "wild",
    "window",
    "bottlesum",
]


reference_vocabulary_path = os.path.join(
    os.path.dirname(__file__), "vocabularies", "seabird_variable_attributes.json"
)
seabird_variable_attributes = seabird_vocabulary()


def _convert_to_netcdf_var_name(var_name):
    """Convert seabird variable name to a netcdf compatible format."""
    return var_name.replace("/", "Per")


def _add_seabird_vocabulary(variable_attributes: dict) -> dict:
    """Match seabird vocabulary to a given variable based on its atributes."""
    for var in variable_attributes:
        var_lower = var.lower()
        if var_lower in seabird_variable_attributes:
            variable_attributes[var].update(seabird_variable_attributes[var_lower])
        elif (
            var.endswith("_sdev")
            and var_lower[:-5] in seabird_variable_attributes.keys()
        ):
            variable_attributes[var].update(seabird_variable_attributes[var_lower[:-5]])
        else:
            logger.warning("Variable %s is missing from vocabulary dictionary", var)
    return variable_attributes


def cnv(
    file_path: str,
    encoding: str = "UTF-8",
    parse_manual_inputs: bool = True,
    generate_instruments_variables: bool = True,
) -> xarray.Dataset:
    """Parse Seabird CNV format generated by Seabird's
    [SBE Data Processing software](https://www.seabird.com/software).

    Args:
        file_path (str): file path
        encoding (str, optional): encoding to use. Defaults to "UTF-8".
        parse_manual_inputs (bool, optional): Attempt to parse the manual
            inputs available in the header ('** lines ...). Defaults to True.
        generate_instruments_variables (bool, optional): Generate instrument
            specific variables based on the IOOS 1.2 convention. Defaults to True.

    Returns:
        xarray.Dataset: Dataset
    """
    original_header = []
    with open(file_path, encoding=encoding) as f:
        while not original_header or "*END*" not in original_header[-1]:
            original_header += f.readline()
        header = parse_seabird_file_header(original_header)
        header["variables"] = _add_seabird_vocabulary(header["variables"])

        df = pd.read_csv(
            f,
            delimiter=r"\s+",
            names=header["variables"].keys(),
            dtype={
                var: var_dtypes.get(var, float) for var in header["variables"].keys()
            },
            na_values=["-1.#IO", "-9.99E-29"],
        )

    ds = _convert_sbe_dataframe_to_dataset(df, header)
    ds = _update_attributes_from_seabird_header(
        ds,
        header["original_header"],
        parse_manual_inputs=parse_manual_inputs,
        generate_instruments_variables=generate_instruments_variables,
    )
    return standardize_dataset(ds)


def btl(
    file_path: str,
    encoding: str = "UTF-8",
    parse_manual_inputs: bool = True,
    generate_instruments_variables: bool = True,
) -> xarray.Dataset:
    """Parse Seabird BTL format generated by Seabird's
    [SBE Data Processing software](https://www.seabird.com/software).

    Args:
        file_path (str): file path
        encoding (str, optional): Encoding to use. Defaults to "UTF-8".
        parse_manual_inputs (bool, optional): Attempt to parse the manual
            inputs available in the header ('** lines ...). Defaults to True.
        generate_instruments_variables (bool, optional): Generate instrument
            specific variables based on the IOOS 1.2 convention. Defaults to True.

    Returns:
        xarray.Dataset: Dataset
    """
    with open(file_path, encoding=encoding) as f:
        original_header = []
        while True:
            original_header += [f.readline()]
            if re.match(r"\s+Bottle", original_header[-1]):
                original_header += [f.readline()]
                break
        header = parse_seabird_file_header("\n".join(original_header))

        # Retrieve variables from bottle header and lower the first letter of each variable
        variable_list = ['bottle','date'] + [var.strip()[0].lower() + var.strip()[1:] for var in re.findall('.{11}',original_header[-2][22:])] + [
            "stats"
        ]
        df = pd.read_fwf(
            f,
            widths=[10, 12] + [11] * (len(variable_list) - 2),
            names=variable_list,
            dtype={var: var_dtypes.get(var, float) for var in variable_list},
        )

    # Split statistical data info separate dateframes
    df["bottle"] = df["bottle"].ffill().astype(int)
    df["stats"] = df["stats"].str.extract(r"\((.*)\)")
    df = df.set_index("bottle")

    # Pivot statistical variables
    df_grouped = df.query("stats=='avg'")
    for stats in df.query("stats!='avg'")["stats"].drop_duplicates().to_list():
        df_grouped = df_grouped.join(df.query("stats==@stats").add_suffix(f"_{stats}"))
    df = df_grouped

    # Generate time variable
    df["time"] = pd.to_datetime(df.filter(like="date").apply(" ".join, axis="columns"))

    # Ignore extra variables
    drop_columns = [col for col in df if re.search("^date|^stats|^bottle_", col)]
    df = df.drop(columns=drop_columns)

    # Retrieve vocabulary associated with each variables
    header["variables"] = {var: header["variables"].get(var, {}) for var in df.columns}
    header["variables"] = _add_seabird_vocabulary(header["variables"])

    # Convert to xarray
    ds = _convert_sbe_dataframe_to_dataset(df, header)

    # Add cell_method attribute
    n_scan_per_bottle = int(
        re.search("# datcnv_scans_per_bottle = (\d+)", header["original_header"])[1]
    )
    for var in ds:
        if var.endswith("_sdev") and var[:-5] in ds:
            ds[var].attrs[
                "cell_method"
            ] = f"scan: standard_deviation (previous {n_scan_per_bottle} scans)"
            # TODO confirm that seabird uses the previous records from this timestamp
        elif var not in ["time", "bottle"]:
            ds[var].attrs[
                "cell_method"
            ] = f"scan: mean (previous {n_scan_per_bottle} scans)"

    ds = _update_attributes_from_seabird_header(
        ds,
        header["original_header"],
        parse_manual_inputs=parse_manual_inputs,
        generate_instruments_variables=generate_instruments_variables,
    )
    return standardize_dataset(ds)


def _convert_sbe_dataframe_to_dataset(df, header):
    """Convert Parsed DataFrame to a dataset"""
    # Convert column names to netcdf compatible format
    df.columns = [_convert_to_netcdf_var_name(var) for var in df.columns]
    header["variables"] = {
        _convert_to_netcdf_var_name(var): attrs
        for var, attrs in header["variables"].items()
    }

    ds = df.to_xarray()
    variable_attributes = header.pop("variables")
    for var, attrs in variable_attributes.items():
        if var not in ds:
            continue
        ds[var].attrs = attrs
    ds.attrs = header
    return ds


def get_seabird_xml_from_header(original_header: str) -> dict:
    def get_xml_section(line_start):
        xml_rows = [
            id
            for id, line in enumerate(original_header.split("\n"))
            if re.match(rf"\{line_start}\s+\<.*", line)
        ]
        if xml_rows:
            return xmltodict.parse(
                f"<temp>{[line[1:] for line in original_header[min(xml_rows):(max(xml_rows)+1)]]}</temp>"
            )["temp"]

    return {"data_xml": get_xml_section("*"), "instrument_xml": get_xml_section("#")}


def parse_seabird_file_header(original_header: str) -> dict:
    """Parsed seabird file header available within
    the different formats: CNV, BTL, and  HEX"""

    def __cast_value(value):
        value = value.strip()
        if sbe_time.match(value):
            return pd.to_datetime(value, format=SBE_TIME_FORMAT)
        elif re.fullmatch(r"\d+", value):
            return int(value)
        elif re.fullmatch(r"[\de\.\+\-]+", value):
            return float(value)
        return value.strip()

    def standardize_attribute(attribute):
        return re.sub(r" |\|\)|\/", "_", attribute.strip()).lower()

    def __get_key_value_attributes(sbe_header):
        attrs = dict(
            [
                row[2:].split("=", 1)
                for row in sbe_header.split("\n")
                if row.startswith(("* ", "# "))
                and "=" in row
                and not re.search(
                    rf'(\*|\#)\s+\<|#\s+name|#\s+span|\#\d+({"|".join(sbe_data_processing_modules)})',
                    row,
                )
            ]
        )
        # Retrieve comments associated with time stamps
        timestamp_attrs = [
            {key: value[:21], f"{key}_comment": value[21:]}
            for key, value in attrs.items()
            if sbe_time.match(value.strip())
        ]
        for items in timestamp_attrs:
            attrs.update(items)

        return {
            standardize_attribute(key): __cast_value(value)
            for key, value in attrs.items()
        }
    

    header = {
        "software_version": re.search(r"\* Software (v|V)ersion (.*)", original_header)[
            1
        ],
        "instrument_type": "".join(
            [
                item
                for item in re.search(
                    r"\* Sea-Bird (.*) Data File\:|\* SBE (.*)", original_header
                ).groups()
                if item
            ]
        ),
        **__get_key_value_attributes(original_header),
        **get_seabird_xml_from_header(original_header),
        "history": get_seabird_cf_history_from_header(original_header),
        "original_header": original_header,
    }

    # Variables
    variables = [
        m.groupdict()
        for m in re.finditer(
            r"\# name (?P<id>\d+) = (?P<sbe_variable>[^\s]+)\: (?P<long_name>.*)"
            + r"( \[(?P<units>.*)\](?P<comments>.*))*",
            header["original_header"],
        )
    ]
    for index, min_span, max_span in re.findall(
        r"\# span (?P<id>\d+) =\s*(?P<min>[e\-\+\d\.]+),\s*(?P<max>[e\-\+\d\.]+)",
        header["original_header"],
    ):
        variables[int(index)].update(
            {"value_min": __cast_value(min_span), "value_max": __cast_value(max_span)}
        )

    header["variables"] = {variable["sbe_variable"]: variable for variable in variables}

    # # btl header row
    # if "Bottle" in line:
    #     header["bottle_columns"] = ["Bottle", "Date"] + list(
    #         map(str.strip, re.findall(".{11}", line[22:-1]))
    #     )
    #     # Read  Position Time line
    #     line = f.readline()
    #     header["original_header"] += line
    return header


def _update_attributes_from_seabird_header(
    ds: xarray.Dataset,
    seabird_header: str,
    parse_manual_inputs: bool = False,
    generate_instruments_variables: bool = True,
    match_instruments_by="long_name",
) -> xarray.Dataset:
    """Add Seabird specific attributes parsed from Seabird header"""
    # sourcery skip: identity-comprehension, remove-redundant-if
    # Instrument
    ds.attrs["instrument"] = _get_seabird_instrument_from_header(seabird_header)

    # Bin Averaged
    ds = _generate_binned_attributes(ds, seabird_header)

    # Manual inputs
    manual_inputs = re.findall(r"\*\* (?P<key>.*): (?P<value>.*)\n", seabird_header)
    if parse_manual_inputs:
        for key, value in manual_inputs:
            ds.attrs[key.replace(r" ", r"_").lower()] = value

    # Generate instruments variables
    if generate_instruments_variables:
        ds = generate_seabird_instruments_variables(
            ds, seabird_header, match_by=match_instruments_by
        )
    return ds


def get_seabird_cf_history_from_header(original_header: str) -> str:
    """Generate CF standard history from Seabird parsed attributes"""

    def make_cf_history_line(module):
        return rf"{pd.to_datetime(module['date'][:20], format=SBE_TIME_FORMAT)} - SBEDataProcessing: {module}".replace(
            "\\\\", "\\"
        )

    sbe_processing_lines = re.findall(
        f"^#\s+(?P<module>{'|'.join(sbe_data_processing_modules)})_(?P<parameter>[^\s]+) = (?P<input>.*)$",
        original_header,
        re.MULTILINE,
    )
    processing = []
    # TODO investigate why duplicated lines are given
    for module, parameter, input in sbe_processing_lines:
        if parameter == "date":
            processing += [{"module": module, parameter: input}]
        elif module == processing[-1]["module"]:
            processing[-1][parameter] = input
        else:
            logger.error("Failed to parse the following sbe processing line: %s")

    return "\n".join([make_cf_history_line(step) for step in processing])


seabird_to_bodc = {
    "Temperature": ["TEMPP681", "TEMPP901", "TEMPS601", "TEMPS901", "TEMPPR01"],
    "Temperature, 2": ["TEMPP682", "TEMPP902", "TEMPS602", "TEMPS902", "TEMPPR02"],
    "Pressure, Digiquartz with TC": ["PRESPR01"],
    "Pressure, Strain Gauge": ["PRESPR01"],
    "Conductivity": ["CNDCST01"],
    "Conductivity, 2": ["CNDCST02"],
    "Altimeter": ["AHSFZZ01"],
    "PAR/Logarithmic, Satlantic": ["IRRDUV01"],
    "PAR/Irradiance, Biospherical/Licor": ["IRRDUV01"],
    "Oxygen, SBE 43": ["DOXYZZ01", "OXYOCPVL01"],
    "Oxygen, SBE 43, 2": ["DOXYZZ02", "OXYOCPVL02"],
    "Oxygen Current, Beckman/YSI": ["DOXYZZ01", "OXYOCPVL01"],
    "Oxygen Temperature, Beckman/YSI": ["DOXYZZ01", "OXYOCPVL01"],
    "Optode 4330F - O2 Temp": ["DOXYZZ01", "OXYTPR01"],
    "Optode 4330F - O2 Temperature": ["DOXYZZ01", "OXYTPR01"],
    "Optode 4330F - O2 D-Phase": ["DOXYZZ01", "OXYOCPFR"],
    "Optode 4330F - D Phase": ["DOXYZZ01", "OXYOCPFR"],
    "Optode 4330F - O2 Concentration": ["DOXYZZ01", "OXYOCPFR"],
    "Fluorometer, Seapoint Ultraviolet": ["CDOMZZ01", "CDOMZZ02"],
    "Fluorometer, WET Labs ECO CDOM": ["CDOMZZ01", "CDOMZZ02"],
    "Fluorometer, Chelsea UV Aquatracka": ["CDOMZZ01", "CDOMZZ02"],
    "Fluorometer, Seapoint": ["CPHLPR01", "CPHLPR02"],
    "Fluorometer, WET Labs WETstar": ["CPHLPR01", "CPHLPR02"],
    "Fluorometer, Wetlabs Wetstar": ["CPHLPR01", "CPHLPR02"],
    "Fluorometer, Wetlab Wetstar": ["CPHLPR01", "CPHLPR02"],
    "Fluorometer, WET Labs ECO-AFL/FL": ["CPHLPR01", "CPHLPR02"],
    "Fluorometer, Seatech/Wetlabs FLF": ["CPHLPR01", "CPHLPR02"],
    "Fluorometer, Chelsea Aqua": ["CPHLPR01", "CPHLPR02"],
    "Fluorometer, Chelsea Aqua 3": ["CPHLPR01", "CPHLPR02"],
    "Fluorometer, Chelsea Minitracka": ["CPHLPR01", "CPHLPR02"],
    "Fluorometer, Seatech/WET Labs FLF": ["CPHLPR01", "CPHLPR02"],
    "Transmissometer, WET Labs C-Star": ["ATTNZS01", "ATTNZR01", "ATTNXXZZ"],
    "Transmissometer, Chelsea/Seatech": ["ATTNZR01", "ATTNXXZZ"],
    "Turbidity Meter, WET Labs, ECO-NTU": ["TURBXX01", "VSCTXX01"],
    "Turbidity Meter, Seapoint": ["TURBXX01", "VSCTXX01"],
    "OBS, Backscatterance (D & A)": ["TURBXX01", "VSCTXX01"],
    "pH": ["PHMASS01", "PHXXZZ01"],
    "OBS, WET Labs, ECO-BB": ["TURBXX01", "VSCTXX01"],
    "OBS, Seapoint Turbidity": ["VSCTXX01", "TURBXX01"],
    "SPAR/Surface Irradiance": ["IRRDSV01"],
    "SPAR, Biospherical/Licor": ["IRRDSV01"],
    "SUNA": [],
    "Dr. Haardt BackScatter Fluorometer": [],
    "User Polynomial": [],
    "User Polynomial, 2": [],
    "User Polynomial, 3": [],
}


def _get_seabird_instrument_from_header(seabird_header: str) -> str:
    """Retrieve main instrument model from Sea-Bird CNV header"""
    instrument = re.findall(
        r"\* (?:Sea\-Bird ){0,1}SBE\s*(?P<sensor>\d+[^\s]*)(?P<extra>.*)",
        seabird_header,
    )
    instrument = [inst for inst, extra in instrument if " = " not in extra]
    if instrument:
        return f"Sea-Bird SBE {''.join(instrument)}"


def _generate_binned_attributes(
    ds: xarray.Dataset, seabird_header: str
) -> xarray.Dataset:
    """Retrieve from the Seabird header binned information and
    apply it to the different related attributes and variable attributes."""

    binavg = re.search(
        r"\# binavg_bintype \= (?P<bintype>.*)\n\# binavg_binsize \= (?P<binsize>\d+)\n",
        seabird_header,
    )
    if binavg:
        bintype, binsize = binavg.groups()
    else:
        return ds

    bin_str = f"{binsize} {bintype}"
    ds.attrs["geospatial_vertical_resolution"] = bin_str
    if "decibar" in bintype:
        binvar = "prdM"
    elif "second" in bin_str or "hour" in bin_str:
        binvar = "time"
    elif "meter" in bin_str:
        binvar = "depth"
    elif "scan" in bin_str:
        binvar = "scan"
    else:
        logger.error("Unknown binavg method: %s", bin_str)

    # Add cell method attribute and geospatial_vertical_resolution global attribute
    if "decibar" in bin_str or "meter" in bin_str:
        ds.attrs["geospatial_vertical_resolution"] = bin_str
    elif "second" in bin_str or "hour" in bin_str:
        ds.attrs["time_coverage_resolution"] = pd.Timedelta(bin_str).isoformat()
    for var in ds:
        if (len(ds.dims) == 1 and len(ds[var].dims) == 1) or binvar in ds[var].dims:
            ds[var].attrs["cell_method"] = f"{binvar}: mean (interval: {bin_str})"
    return ds


def generate_seabird_instruments_variables(
    ds: xarray.Dataset, seabird_header: str, match_by: str = "long_name"
) -> xarray.Dataset:
    """Extract seabird sensor information and generate instrument variables which
    follow the IOOS 1.2 convention. The instrument variables are then matched
    to their respective data.

    Args:
        ds (xarray.Dataset): dataset
        seabird_header (str): original seabird header
        match_by (str, optional): Attribute used to matched the instruments to
            their associated variables. Defaults to "long_name".
                + "long_name": expect the original seabird long name
                + "sdn_parameter_urn": Match via the BODC variable.
                  (see seabird to bodc mapping in
                  ocean_data_parser/parsers/seabird.py)

    Returns:
        xarray.Dataset: dataset with extra instruments variables.
    """
    # Retrieve sensors information
    if "# <Sensors count" in seabird_header:
        ds, sensors_map = _generate_instruments_variables_from_xml(ds, seabird_header)
    elif "# sensor" in seabird_header:
        ds = _generate_instruments_variables_from_sensor(ds, seabird_header)
        logger.info("Unable to map old seabird sensor header to appropriate variables")
        return ds
    else:
        # If no calibration detected give a warning and return dataset
        logger.info("No Seabird sensors information was detected")
        return ds

    ds = _generate_instruments_attributes(ds, sensors_map, match_by)

    return ds


def _generate_instruments_attributes(
    ds, sensors_map: dict, match_by="long_name"
) -> xarray.Dataset:
    def _add_instrument(var, instrument):
        """Append to instrument attribute"""
        if "instrument" not in ds[var].attrs:
            ds[var].attrs["instrument"] = instrument
        else:
            ds[var].attrs["instrument"] += f",{instrument}"

    # Match instrument variables to their associated variables
    for name, sensor_variable in sensors_map.items():
        if match_by == "sdn_parameter_urn":
            if name not in seabird_to_bodc:
                logger.warning("Missing Seabird to BODC mapping of: %s", name)
                continue
            values = [f"SDN:P01::{item}" for item in seabird_to_bodc[name]]
        else:
            values = [name]

        for value in values:
            matched_variables = ds.filter_by_attrs(**{match_by: value})
            if not matched_variables:
                logger.warning("Failed to match instrument %s to any variables.", name)
                continue

            # Some variables are not necessearily BODC specifc
            # we'll try to match them based on the long_name
            if (
                len(matched_variables) > 1
                and match_by == "sdn_parameter_urn"
                and ("Fluorometer" in name or "Turbidity" in name)
            ):
                # Find the closest match based on the file name
                var_longname = difflib.get_close_matches(
                    name,
                    [
                        matched_variables[var].attrs["long_name"]
                        for var in matched_variables
                    ],
                )
                matched_variables = matched_variables[
                    [
                        var
                        for var in matched_variables
                        if ds[var].attrs["long_name"] in var_longname
                    ]
                ]

                # If there's still multiple matches give a warning
                if len(matched_variables) > 1:
                    logger.warning(
                        "Unable to link multiple %s instruments via sdn_parameter_urn attribute.",
                        name,
                    )

            for var in matched_variables:
                _add_instrument(var, sensor_variable)
    return ds


def _generate_instruments_variables_from_xml(
    ds: xarray.Dataset, seabird_header: str
) -> xarray.Dataset:
    """Generate IOOS 1.2 standard instrument variables and associated variables
    instrument attribute based on Seabird XML header."""
    # Retrieve Sensors xml section within seabird header
    calibration_xml = re.sub(
        r"\n\#\s",
        r"\n",
        re.search(r"\<Sensors .+\<\/Sensors\>", seabird_header, re.DOTALL)[0],
    )

    # Read XML and commented lines, drop encoding line
    try:
        sensors = xmltodict.parse(calibration_xml)["Sensors"]["sensor"]
    except ExpatError:
        logger.error("Failed to parsed Sea-Bird Instrument Calibration XML")
        return ds, {}

    sensors_comments = re.findall(
        r"\s*\<!--\s*(Frequency \d+|A/D voltage \d+|.* voltage|Count){1}, (.*)-->\n",
        calibration_xml,
    )
    # Consider only channels with sensor mounted
    sensors = [sensor for sensor in sensors if len(sensor) > 1]
    sensors_comments = [
        (con, name)
        for con, name in sensors_comments
        if not name.startswith(("Free", "Unavailable"))
    ]

    # Make sure that the sensor count match the sensor_comments count
    if len(sensors_comments) != len(sensors):
        logger.error("Failed to detect same count of sensors and sensors_comments")
        return ds, {}

    # Split each sensor calibrations to a dictionary
    sensors_map = {}
    for sensor, sensor_comment in zip(sensors, sensors_comments):
        sensor_key = list(sensor.keys())[1].strip()
        attrs = sensor[sensor_key]
        channel, description = sensor_comment

        # Define senor variable name
        if "UserPolynomial" in sensor_key and attrs.get("SensorName"):
            sensor_name = attrs.pop("SensorName").strip()
            sensor_var_name = re.sub(r"[^\d\w]+", "_", sensor_name)
        else:
            sensor_var_name = sensor_key
            sensor_name = description.strip()

        if "Oxygen" in sensor_name:
            subsensors = re.search(r"Current|Temp|Phase|Concentration", description)
            if subsensors:
                sensor_var_name += "_" + subsensors[0]

        # Add trailing number if present
        if re.search(r", \d+", sensor_name):
            sensor_number = int(re.search(r", (\d+)", sensor_name)[1])
            sensor_var_name += f"_{sensor_number}"
        else:
            sensor_number = 1

        if sensor_var_name in ds:
            logger.warning("Duplicated instrument variable %s", sensor_var_name)

        # Try fit IOOS 1.2 which request to add a instrument variable for each
        # instruments and link this variable to data variable by using the instrument attribute
        # https://ioos.github.io/ioos-metadata/ioos-metadata-profile-v1-2.html#instrument
        ds[sensor_var_name] = json.dumps(attrs)
        ds[sensor_var_name].attrs = {
            "calibration_date": convert_datetime_str(
                attrs.pop("CalibrationDate"),
                errors="ignore",
            ),  # IOOS 1.2, NCEI 2.0
            "component": f"{sensor_var_name}_sn{attrs['SerialNumber']}",  # IOOS 1.2
            "discriminant": str(sensor_number),  # IOOS 1.2
            "make_model": sensor_name,  # IOOS 1.2, NCEI 2.0
            "channel": channel,
            "sbe_sensor_id": int(attrs.pop("@SensorID")),
            "serial_number": attrs.pop("SerialNumber"),  # NCEI 2.0
            "calibration": json.dumps(attrs),
        }
        sensors_map[sensor_name] = sensor_name

    return ds, sensors_map


def _generate_instruments_variables_from_sensor(
    dataset: xarray.Dataset, seabird_header: str
) -> xarray.Dataset:
    """Parse older Seabird Header sensor information and generate instrument variables"""
    sensors = re.findall(r"\# sensor (?P<id>\d+) = (?P<text>.*)\n", seabird_header)
    for index, sensor in sensors:
        if "Voltage" in sensor:
            sensor_items = sensor.split(",", 1)
            attrs = {
                "channel": sensor_items[0],
                "sensor_description": sensor_items[0].replace("Voltage", "").strip()
                + sensor_items[1],
            }
        else:
            attrs_dict = re.search(
                r"(?P<channel>Frequency\s+\d+|Stored Volt\s+\d+|Extrnl Volt  \d+|Pressure Number\,)\s+"
                + r"(?P<sensor_description>.*)",
                sensor,
            )
            if attrs_dict is None:
                logger.error("Failed to read sensor item: %s", sensor)
                continue
            attrs = attrs_dict.groupdict()
        sensor_code = f"sensor_{index}"
        dataset[sensor_code] = sensor
        dataset[sensor_code].attrs = attrs
    return dataset
