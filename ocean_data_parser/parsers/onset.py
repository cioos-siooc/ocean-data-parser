"""
[Onset](https://www.onsetcomp.com/) is a company that manufactures
data loggers and sensors for environmental monitoring.
Their Hobo data loggers are widely used for monitoring water
quality parameters such as temperature, conductivity, and light
intensity. The present module provides a parser for the CSV files
generated by the HOBOware software.
"""

import logging
import re
from csv import reader
from datetime import datetime
from typing import Union

import numpy as np
import pandas as pd
import xarray
from dateutil.parser._parser import ParserError

from ocean_data_parser.parsers.utils import standardize_dataset

GLOBAL_ATTRIBUTES = {"Convention": "CF-1.6"}

logger = logging.getLogger(__name__)
VARIABLE_NAME_MAPPING = {
    "#": "record_number",
    "Date Time": "time",
    "Temp": "temperature",
    "Intensity": "light_intensity",
    "Specific Conductance": "specific_conductance",
    "Low Range": "low_range",
    "EOF": "end_of_file",
    "End of File": "end_of_file",
    "Abs Pres Barom.": "barometric_pressure",
    "Pressure Barom.": "barometric_pressure",
    "Abs Pres": "pressure",
    "Sensor Depth": "sensor_depth",
    "Turbidity": "turbidity",
    "Water Level": "water_level",
}

IGNORED_VARIABLES = [
    "record_number",
    "time",
    "button_up",
    "button_down",
    "host_connected",
    "end_of_file",
    "coupler_detached",
    "coupler_attached",
    "stopped",
    "started",
    "good_battery",
    "bad_battery",
    "host_connect",
    "batt",
    "low_power",
    "water_detect",
    "record",
    "eof",
    "",
]

DATETIME_REGEX_FORMATS = [
    (r"\d\d\/\d\d\/\d\d\s+\d\d\:\d\d\:\d\d\s+\w\w", r"%m/%d/%y %I:%M:%S %p"),
    (r"\d\d\d\d\/\d\d\/\d\d\s+\d\d\:\d\d\:\d\d\s+\w\w", r"%Y/%m/%d %I:%M:%S %p"),
    (r"\d\d\/\d\d\/\d\d\s+\d\d\:\d\d", r"%m/%d/%y %H:%M"),
    (r"\d\d\/\d\d\/\d\d\d\d\s+\d\d\:\d\d\:\d\d\s+(AM|PM)", r"%m/%d/%Y %H:%M:%S %p"),
    (r"\d+\/\d+\/\d\d\s+\d\d\:\d\d", r"%m/%d/%y %H:%M"),
    (r"^\d\d\d\d\-\d\d\-\d\d\s+\d\d\:\d\d\:\d\d$", r"%Y-%m-%d %H:%M:%S"),
    (r"\d\d\d\d\-\d\d\-\d\d\s+\d\d\:\d\d\:\d\d (AM|PM)", r"%Y-%m-%d %I:%M:%S %p"),
    (r"^\d\d\-\d\d\-\d\d\s+\d{1,2}\:\d\d$", r"%y-%m-%d %H:%M"),
    (r"^\d\d\-\d\d\-\d\d\s+\d{1,2}\:\d\d\:\d\d$", r"%y-%m-%d %H:%M:%S"),
    (r"^\d\d\d\d\-\d\d\-\d\d\s+\d{1,2}\:\d\d$", r"%Y-%m-%d %H:%M"),
    (r"^\d{1,2}\/\d{1,2}\/\d\d\d\d\s\d{1,2}\:\d\d", r"%m/%d/%Y %H:%M"),
    (r"^\d\d\d\d\-\d\d\-\d\d\s+\d{1,2}:\d\d:\d\d (AM|PM)", r"%Y-%m-%d %I:%M:%S %p"),
]


def _get_time_format(time):
    for regex, datetime_format in DATETIME_REGEX_FORMATS:
        if re.fullmatch(regex, time):
            return datetime_format
    return None


def _parse_onset_csv_header(header_lines):
    full_header = "\n".join(header_lines)
    header = {
        "instrument_manufacturer": "Onset",
        "history": "",
        "timezone": re.search(r"GMT\s*([\-\+\d\:]*)", full_header),
        "plot_title": re.search(r"Plot Title\: (\w*),+", full_header),
        "logger_sn": ",".join(set(re.findall(r"LGR S\/N\: (\d*)", full_header))),
        "sensor_sn": ",".join(set(re.findall(r"SEN S\/N\: (\d*)", full_header))),
        "instrument_sn": ",".join(
            set(
                re.findall(r"(?:SEN S\/N|LGR S\/N|Serial Number):\s*(\d+)", full_header)
            )
        ),
        "lbl": ",".join(set(re.findall(r"lbl: (\d*)", full_header))),
    }

    header = {
        key: value[1] if isinstance(value, re.Match) else value
        for key, value in header.items()
    }
    # Handle Columns
    original_columns = list(reader([header_lines[-1]], delimiter=",", quotechar='"'))[0]
    variables = {}
    for col in original_columns:
        # Ignore plot title from column names
        if header["plot_title"]:
            col = col.replace(header["plot_title"], "")

        column_with_units = re.sub(
            r"\s*\(*(LGR S\/N|SEN S\/N|LBL): .*",
            "",
            col,
        )
        column = re.split(r"\,|\(|\)", column_with_units)[0].strip()
        variables[column] = {
            "original_name": col,
            "units": re.split(r"\,|\(", column_with_units.replace(")", "").strip())[
                -1
            ].strip()
            if re.search(r"\,|\(", column_with_units)
            else None,
        }

    header["time_variables"] = [var for var in variables if "Date Time" in var]

    if header["timezone"] is None:
        logger.warning("No Timezone available within this file. UTC will be assumed.")
        header["timezone"] = "UTC"

    return header, variables


def _standardized_variable_mapping(variables):
    """Standardize onset variable names"""
    return {
        var: VARIABLE_NAME_MAPPING[var]
        if var in VARIABLE_NAME_MAPPING
        else var.lower().replace(" ", "_")
        for var in variables
    }


def csv(
    path: str,
    convert_units_to_si: bool = True,
    standardize_variable_names: bool = True,
    encoding: str = "UTF-8",
    errors: str = "strict",
) -> xarray.Dataset:
    """Parses the Onset CSV format generate by HOBOware into a xarray object

    Inputs:
        path: The path to the CSV file
        convert_units_to_si: Whether to standardize data units to SI units
        standardize_variable_names: Rename the variable names a standardize name
        convention
        encoding: File encoding. Defaults to "utf-8"
        errors: Error handling. Defaults to "strict"
    Returns:
        xarray.Dataset
    """

    raw_header = []
    with open(
        path,
        encoding=encoding,
        errors=errors,
    ) as f:
        raw_header += [f.readline().replace("\n", "")]
        header_lines = 1
        if "Serial Number:" in raw_header[0]:
            # Some historical format have an extra line after initial serial number
            # skip second empty line
            header_lines += 1
            f.readline()  #
        # Read csv columns
        raw_header += [f.readline()]
        first_row = f.readline()
        date_format = _get_time_format(first_row.split(",")[1])

    # Parse onset header
    header, variables = _parse_onset_csv_header(raw_header)

    # Inputs to pd.read_csv
    consider_columns = {
        var: id
        for id, var in enumerate(variables.keys())
        if var.lower().replace(" ", "_") not in IGNORED_VARIABLES
    }
    df = pd.read_csv(
        path,
        na_values=[" "],
        skiprows=list(range(header_lines + 1)),
        parse_dates=["Date Time"],
        date_format=date_format,
        sep=",",
        header=None,
        memory_map=True,
        names=consider_columns.keys(),
        usecols=consider_columns.values(),
        encoding_errors=errors,
        encoding=encoding,
    )

    # Add timezone to time variables
    df["Date Time"] = df["Date Time"].dt.tz_localize(header["timezone"])

    # Convert to dataset
    ds = df.to_xarray()
    ds.attrs = {**GLOBAL_ATTRIBUTES, **header}
    for var in ds:
        ds[var].attrs = variables[var]

    if standardize_variable_names:
        ds = ds.rename_vars(_standardized_variable_mapping(ds))
        # Detect instrument type based on variables available
        ds.attrs["instrument_type"] = _detect_instrument_type(ds)

    # # Review units and convert SI system
    if convert_units_to_si:
        if standardize_variable_names:
            if "temperature" in ds and ("C" not in ds["temperature"].attrs["units"]):
                logger.warning("Temperaure in farenheit will be converted to celsius")
                ds["temperature"] = _farenheit_to_celsius(ds["temperature"])
                ds["temperature"].attrs["units"] = "degC"
                ds.attrs["history"] += " ".join(
                    [
                        f"{datetime.now()}",
                        f"Convert temperature ({ ds['temperature'].attrs['units']}) to"
                        "degree Celsius [(degF-32)/1.8000]",
                    ]
                )
            if (
                "conductivity" in ds
                and "uS/cm" not in ds["conductivity"].attrs["units"]
            ):
                logger.warning(
                    "Unknown conductivity units (%s)", ds["conductivity"].attrs["units"]
                )
        else:
            logger.warning(
                "Unit conversion is not supported if standardize_variable_names=False"
            )

    # Test daylight saving issue
    # TODO move this daylight saving detection test elsewhere
    dt = ds["time"].diff("index")
    sampling_interval = dt.median().values
    dst_fall = -pd.Timedelta("1h") + sampling_interval
    dst_spring = pd.Timedelta("1h") + sampling_interval
    if any(dt == dst_fall):
        logger.warning(
            (
                "Time gaps (=%s) for sampling interval of %s "
                "suggest a Fall daylight saving issue is present"
            ),
            dst_fall,
            sampling_interval,
        )
    if any(dt == dst_spring):
        logger.warning(
            (
                "Time gaps (=%s) for sampling interval of %s "
                "suggest a Spring daylight saving issue is present"
            ),
            dst_fall,
            sampling_interval,
        )

    ds = standardize_dataset(ds)
    return ds


def _detect_instrument_type(ds):
    """Detect instrument type based on variables available in the dataset."""
    # Try to match instrument type based on variables available (this information is
    # unfortnately not available withint the CSV)
    vars_of_interest = {
        var
        for var in ds
        if var not in IGNORED_VARIABLES and not var.startswith("unnamed")
    }

    if vars_of_interest == {"temperature", "light_intensity"}:
        instrument_type = "Pendant"
    elif vars_of_interest == {"specific_conductance", "temperature", "low_range"}:
        instrument_type = "CT"
    elif vars_of_interest == {"temperature", "specific_conductance"}:
        instrument_type = "CT"
    elif vars_of_interest == {"temperature"}:
        instrument_type = "Tidbit"
    elif vars_of_interest == {"temperature", "sensor_depth"}:
        instrument_type = "PT"
    elif vars_of_interest == {"temperature", "pressure", "sensor_depth"}:
        instrument_type = "PT"
    elif vars_of_interest == {
        "temperature",
        "barometric_pressure",
        "pressure",
        "sensor_depth",
    }:
        instrument_type = "WL"
    elif vars_of_interest == {
        "temperature",
        "barometric_pressure",
        "pressure",
        "water_level",
    }:
        instrument_type = "WL"
    elif vars_of_interest == {"temperature", "pressure"}:
        instrument_type = "airPT"
    elif vars_of_interest == {"barometric_pressure"}:
        instrument_type = "airP"
    elif vars_of_interest == {"turbidity"}:
        instrument_type = "turbidity"
    else:
        instrument_type = "unknown"
        logger.warning(
            "Unknown Hobo instrument type with variables: %s", vars_of_interest
        )
    return instrument_type


def _farenheit_to_celsius(farenheit):
    """Convert temperature in Farenheit to Celcius
    Args:
        farenheit (float): Temperature in Farenheint

    Returns:
        float: Temperature in celsisus
    """
    return (farenheit - 32.0) / 1.8000
